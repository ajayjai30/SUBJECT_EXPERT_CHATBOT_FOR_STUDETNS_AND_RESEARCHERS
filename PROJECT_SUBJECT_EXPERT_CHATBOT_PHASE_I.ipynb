{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayjai30/SUBJECT_EXPERT_CHATBOT_FOR_STUDETNS_AND_RESEARCHERS/blob/main/PROJECT_SUBJECT_EXPERT_CHATBOT_PHASE_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR1C0v-U6k1k"
      },
      "source": [
        "#Section-1 Libraries and Dependencies Installation and setting up of libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TypPHs_p-qvc"
      },
      "source": [
        "Dependencies installation section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Y_IofOHb-Gwt",
        "outputId": "4c03b5f4-7fef-4800-ba1c-8e7479b45cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.12 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.41.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.112.0)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.41.0-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, tomlkit, semantic-version, ruff, python-multipart, ffmpy, aiofiles, gradio-client, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.0\n",
            "    Uninstalling tomlkit-0.13.0:\n",
            "      Successfully uninstalled tomlkit-0.13.0\n",
            "Successfully installed aiofiles-23.2.1 ffmpy-0.4.0 gradio-4.41.0 gradio-client-1.3.0 pydub-0.25.1 python-multipart-0.0.9 ruff-0.5.7 semantic-version-2.10.0 tomlkit-0.12.0\n"
          ]
        }
      ],
      "source": [
        "#dependencies installation\n",
        "!pip install -q --upgrade google-generativeai langchain-google-genai chromadb pypdf\n",
        "!sudo apt-get -y -qq install poppler-utils\n",
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "!pip install -q --upgrade google-generativeai langchain-google-genai chromadb pypdf\n",
        "!sudo apt-get -y -qq install poppler-utils libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n",
        "!sudo apt -y -qq install tesseract-ocr libtesseract-dev# for embedding of text inside images\n",
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install gradio\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "JaKs0tZHzmhF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do62alvO-vMX"
      },
      "source": [
        "Libraries Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6NlAyEXBn-g"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import os#for file handling purposes\n",
        "from google.colab import userdata#used for storing public data when processing Here api will be stone and also for accesing secret access key.\n",
        "import google.generativeai as genai#library for using LLM model with all features given by google\n",
        "import urllib\n",
        "from pathlib import Path as p\n",
        "from pprint import pprint\n",
        "import textwrap#For adjusting line breaks and adding indentation inside markdown.\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from IPython.display import display,Markdown#for displaying information as output\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FwcG_3--7zR"
      },
      "source": [
        "***Function for editing the response style and also using text to speech methods for additional functionality***\n",
        "\n",
        "\n",
        "Overall Functionality:\n",
        "\n",
        "The to_markdown function takes plain text as input, converts bullet points to Markdown-style lists, indents all lines to create a blockquote, and returns the result as a Markdown object. This is useful for converting text into a format suitable for display on platforms that support Markdown, such as GitHub, Reddit, or various blogging platforms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DME7DAw5WnhC"
      },
      "outputs": [],
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE7zT7TTGWdO"
      },
      "source": [
        "#API key setup and verification of models availability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p8K670B_aJI"
      },
      "source": [
        "Section-1\n",
        "setting up the configuration of Model from api key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab9ASynfcIZn"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqJY2YQRADVr"
      },
      "source": [
        "verification of models for synchronizing with the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "712dYybMG5ve",
        "outputId": "d220cf11-0de4-441e-bde2-7b6895d0049e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-exp-0801\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001-tuning\n"
          ]
        }
      ],
      "source": [
        "for model in genai.list_models():\n",
        "  if 'generateContent' in model.supported_generation_methods:\n",
        "    print(model.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7_WRak92HPz"
      },
      "source": [
        "#Environment creation and Initialization of model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpN73FfkERXa"
      },
      "source": [
        "Setting up the environment for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uyw4ILkEQ9J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY']=userdata.get(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK7MZmoi1VEq"
      },
      "source": [
        "Initiating the model inside the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wE5FqP1TlYp"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSmGPjIKWebm"
      },
      "source": [
        "#Extracting text from pdf files located in drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy__LhNIhgNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed0466e-552a-4f78-cb46-4dfac076b2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2XsCxEjejzU"
      },
      "outputs": [],
      "source": [
        "os.listdir(Main_path)[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBBAUE9wehOH",
        "outputId": "a950781d-a8d3-4a01-df34-11ecd1827b0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CobXTnVYYtOB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "all_pages=[]\n",
        "Main_path='/content/drive/MyDrive/contentconvertedpdf'\n",
        "\n",
        "for i in range(len(os.listdir(Main_path))):\n",
        "     j=os.path.join(Main_path,os.listdir(Main_path)[i])\n",
        "     pdf_loader = PyPDFLoader(j)\n",
        "     pages = pdf_loader.load_and_split()\n",
        "     all_pages.extend(pages)\n",
        "\n",
        "#print(all_pages[5].page_content)  # Can Be used as a verification for Printing the content of the first page of the first PDF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#workings on problem"
      ],
      "metadata": {
        "id": "1VHDyw4vhOu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itfCs-lu9cyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e7e9ca-2d30-4cb3-b45d-c61240a1a571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Collecting pytesseract==0.3.10\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract==0.3.10) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract==0.3.10) (9.4.0)\n",
            "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ],
      "source": [
        "!pip install pdf2image\n",
        "!pip install pytesseract==0.3.10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "from pytesseract import image_to_string as s\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "GvGpXciD9jEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_img_from_pdf(pdf_file_path):\n",
        "  return convert_from_path(pdf_file_path)"
      ],
      "metadata": {
        "id": "XuIKPogv-YMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_image(file):\n",
        "  return s(file)"
      ],
      "metadata": {
        "id": "ldlhojO3-1uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pages=[]\n",
        "Main_path='/content/drive/MyDrive/contentconvertedpdf'\n",
        "for i in range(len(os.listdir(Main_path))):\n",
        "  j=os.path.join(Main_path,os.listdir(Main_path)[i])\n",
        "  if j.endswith('.pdf'):\n",
        "    images=convert_to_img_from_pdf(j)\n",
        "    for img in images:\n",
        "      all_pages.append(extract_text_from_image(img))\n",
        "  else:\n",
        "    continue"
      ],
      "metadata": {
        "id": "NxxxHaPl_hQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHusG4BtEJ8D",
        "outputId": "b1aaf720-ce0c-492e-a7f0-b801c88f3d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six) (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/5.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/5.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20240706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = extract_text(pdf_path)\n",
        "    return text\n",
        "\n",
        "all_pages = []\n",
        "Main_path = '/content/drive/MyDrive/ContentforModelFluidMechanics'\n",
        "\n",
        "for file in os.listdir(Main_path):\n",
        "    if file.endswith('.pdf'):\n",
        "        pdf_path = os.path.join(Main_path, file)\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        all_pages.append(text)\n",
        "\n",
        "print(all_pages)\n"
      ],
      "metadata": {
        "id": "LB7VQJt4EIBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from multiprocessing import Pool\n",
        "import pdf2image\n",
        "import pytesseract\n",
        "\n",
        "def process_pdf(pdf_path):\n",
        "    images = pdf2image.convert_from_path(pdf_path)\n",
        "    text_data = []\n",
        "    for img in images:\n",
        "        text = pytesseract.image_to_string(img)\n",
        "        text_data.append(text)\n",
        "    return text_data\n",
        "\n",
        "def main():\n",
        "    all_pages = []\n",
        "    Main_path = '/content/drive/MyDrive/contentconvertedpdf'\n",
        "\n",
        "    with Pool(processes=4) as pool:  # Adjust number of processes as needed\n",
        "        all_pages = pool.map(process_pdf, [os.path.join(Main_path, f) for f in os.listdir(Main_path) if f.endswith('.pdf')])\n",
        "\n",
        "    # Flatten the list of lists\n",
        "    all_pages = [page for sublist in all_pages for page in sublist]\n",
        "\n",
        "    print(all_pages)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "eO_5l9AoGRrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBLkRCfp82cd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import pytesseract\n",
        "import pdfplumber\n",
        "from PIL import Image\n",
        "\n",
        "def extract1_text_from_pdf(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'rb') as pdf_file:\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "            all_text = []\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                all_text.append(page.extract_text())\n",
        "\n",
        "                try:\n",
        "                    with pdfplumber.open(file_path) as pdf:\n",
        "                        page_obj = pdf.pages[page_num]\n",
        "                        images = page_obj.extract_images()\n",
        "                        for image in images:\n",
        "                            image_data = image[\"data\"]\n",
        "                            img = Image.frombytes(mode=image[\"colorspace\"], size=image[\"size\"], data=image_data)\n",
        "                            try:\n",
        "                                text = pytesseract.image_to_string(img)\n",
        "                                all_text.append(text)\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error processing image: {e}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing PDF images: {e}\")\n",
        "\n",
        "            return all_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "# rest of the code remaining the same\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvmGcOYXAOmg",
        "outputId": "1793f5ab-72ba-4614-ff34-4a178c879b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pymupdf==1.22.0\n",
            "  Downloading PyMuPDF-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Downloading PyMuPDF-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf==1.22.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpqU4HzsAEn4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    try:\n",
        "        doc = fitz.open(file_path)\n",
        "        all_text = []\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc[page_num]\n",
        "            all_text.append(page.get_text())\n",
        "\n",
        "            # Extract images\n",
        "            for img in page.get_images():\n",
        "                xref = img[0]\n",
        "                base_image = doc.extract_image(xref)\n",
        "                image_bytes = base_image[\"image\"]\n",
        "                img = Image.frombytes(mode=base_image[\"colorspace\"], size=base_image[\"size\"], data=image_bytes)\n",
        "                try:\n",
        "                    text = pytesseract.image_to_string(img)\n",
        "                    all_text.append(text)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing image: {e}\")\n",
        "\n",
        "        doc.close()\n",
        "        return all_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "# ... rest of the code remains the same\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww7x2mC8A5YD",
        "outputId": "0d0b7c6f-8ae8-412a-d92d-217aeca99891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing file /content/drive/MyDrive/ContentforModelFluidMechanics/2500solvedproblemsinfluidmechanicshydraulics.pdf: 'image_info'\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import fitz\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    try:\n",
        "        doc = fitz.open(file_path)\n",
        "        all_text = []\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc[page_num]\n",
        "            all_text.append(page.get_text())\n",
        "\n",
        "            # Extract images\n",
        "            for img in page.get_images():\n",
        "                xref = img[0]\n",
        "                base_image = doc.extract_image(xref)\n",
        "                image_bytes = base_image[\"image\"]\n",
        "                image_info = base_image[\"image_info\"]\n",
        "\n",
        "                try:\n",
        "                    img = Image.frombytes(mode=image_info[\"cs\"], size=(image_info[\"w\"], image_info[\"h\"]), data=image_bytes)\n",
        "                except Exception as e:\n",
        "                    try:\n",
        "                        img = Image.fromarray(np.array(image_bytes).reshape((image_info[\"h\"], image_info[\"w\"], 3)), mode='RGB')\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing image: {e}\")\n",
        "                        continue\n",
        "\n",
        "                try:\n",
        "                    text = pytesseract.image_to_string(img)\n",
        "                    all_text.append(text)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing image text: {e}\")\n",
        "\n",
        "        doc.close()\n",
        "        return all_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file_path}: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_text_from_directory(directory):\n",
        "    all_text = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.pdf'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                page_text = extract_text_from_pdf(file_path)\n",
        "                all_text.extend(page_text)\n",
        "    return all_text\n",
        "\n",
        "# Example usage\n",
        "Main_path = '/content/drive/MyDrive/ContentforModelFluidMechanics'\n",
        "all_text = extract_text_from_directory(Main_path)\n",
        "print(all_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trying to use lamma-parser**"
      ],
      "metadata": {
        "id": "lMs8oQZH0Wdq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qdctCZGy0Vu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh_9iITcYY33"
      },
      "source": [
        "#Building pipeline for rag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OvzKNtlqfHV"
      },
      "source": [
        "Here the flow of pipeline is shown below\n",
        "\n",
        "\n",
        "**pdf==> text generated as chunks ==>chunks converted into embeddings==> uploaded into chroma data base**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHtb-LJDcvLe"
      },
      "outputs": [],
      "source": [
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=10)\n",
        "content=\"n\\n\".join(str(p.page_content) for p in all_pages)\n",
        "text_chunks=text_splitter.split_text(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gay50PuwdUWb"
      },
      "outputs": [],
      "source": [
        "embeddings=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=userdata.get(\"GOOGLE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Agj5ZoaDdmht"
      },
      "outputs": [],
      "source": [
        "vector_index = Chroma.from_texts(text_chunks, embeddings).as_retriever(search_kwargs={\"k\":5})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7C8FdjBv67U"
      },
      "source": [
        "#Question answer bot final step before fine tuning the answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_oY_Uwd1-IR"
      },
      "outputs": [],
      "source": [
        "template_for_prompt_response=\"\"\"\n",
        "Use the following pieces of context to answer the question at the end. If the question is not related to the context, politely respond that you are tuned to only answer questions that are related to the context.\n",
        "dont make up your own answers. Explain to the question with maximum answer that u can give. Always greet with Thanks for asking i am happy to help you out only at the end of the answer.\n",
        "Also greet them when they are saying thankyou or related to thank you.\n",
        "\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\n",
        "\"\"\"\n",
        "Question_answer_chain_promt_adjusting_control=PromptTemplate.from_template(template_for_prompt_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgbnJkLU1cnh"
      },
      "outputs": [],
      "source": [
        "Question_answer_chain=RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=vector_index,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={'prompt':Question_answer_chain_promt_adjusting_control}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlJ8pSeGrHw-"
      },
      "source": [
        "#Testing with temporary hosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkwtV9yapK-3"
      },
      "outputs": [],
      "source": [
        "import gradio as g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "pHJ6L2aXrpZL",
        "outputId": "4dabd1f9-0362-448b-fb89-0c486f1bdc51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://b463af4a0933ec2a7d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b463af4a0933ec2a7d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def text_response(Question):\n",
        "  question=Question\n",
        "  result=Question_answer_chain({\"query\":question})\n",
        "  return result['result']\n",
        "\n",
        "# Create a Gradio interface\n",
        "interface = g.Interface(fn=text_response, inputs=\"text\", outputs='markdown',description='This chatbot is trained on a particular subject with the contents available related to the particular subject.',title='SUBJECT EXPERT CHATBOT TESTING PHASE-1')\n",
        "\n",
        "# Launch the Gradio interface\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_nJlreZXKZaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using lamma parse"
      ],
      "metadata": {
        "id": "MOQ1-jY4Ka5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-parse\n",
        "!pip install llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k_HluQ5SKiq9",
        "outputId": "229b3bdc-9eec-496b-a54c-4aa49acd5f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed llama-cloud-0.0.13 llama-index-0.10.65 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48.post1 llama-index-llms-openai-0.1.29 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 pypdf-4.3.1 striprtf-0.0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from IPython.display import display,Markdown\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "8hXmYcnlLZlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/ContentforModelFluidMechanics'"
      ],
      "metadata": {
        "id": "aOO6sfpHMWk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment if you are in a Jupyter Notebook\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from llama_parse import LlamaParse  # pip install llama-parse\n",
        "from llama_index.core import SimpleDirectoryReader  # pip install llama-index\n",
        "\n",
        "parser = LlamaParse(\n",
        "    api_key=userdata.get('LAMMA_PARSE_API_KEY'),  # can also be set in your env as LLAMA_CLOUD_API_KEY\n",
        "    result_type=\"markdown\"  # \"markdown\" and \"text\" are available\n",
        ")\n",
        "\n",
        "file_extractor = {\".pdf\": parser}\n",
        "reader = SimpleDirectoryReader(path, file_extractor=file_extractor)\n",
        "documents = reader.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am3MXedJQokO",
        "outputId": "8caeb68f-ec52-4c98-80ea-e57dc64d51aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id c8e6a685-b75c-4675-af3c-996c16887909\n",
            "........................................................................"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnHw_4m_e0OI",
        "outputId": "fa59f680-245c-4846-e590-706ca48338eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "807"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(documents[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "kDcFmLa_XedZ",
        "outputId": "51eab2a5-90e4-41c7-9f01-bc25b60a8a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'text'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b647467b585f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mto_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'text'"
          ]
        }
      ]
    },
    {
      "source": [
        "# Define the file name\n",
        "file_name = \"fluidmechanics2500solvedproblems_extracted_file.txt\"\n",
        "\n",
        "# Create the file (if it doesn't exist) and open it in write mode\n",
        "with open(file_name, \"w\") as file:\n",
        "  pass  # Do nothing here, just creating the file\n",
        "\n",
        "# Now, open the file in append mode to add content\n",
        "with open(file_name, \"a\") as file:\n",
        "  for i in range(len(documents)):\n",
        "    file.write(documents[i].text)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "NHgsrSNxfGmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4SMpGYzrfbmH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "KR1C0v-U6k1k",
        "AE7zT7TTGWdO",
        "z7_WRak92HPz",
        "gSmGPjIKWebm",
        "1VHDyw4vhOu3",
        "nh_9iITcYY33",
        "P7C8FdjBv67U",
        "XlJ8pSeGrHw-"
      ],
      "provenance": [],
      "mount_file_id": "1L9O6aeO_hPYXwI4UX6iIRooi-P9w_bYF",
      "authorship_tag": "ABX9TyNDMCq4esA/grdNi3isMrLA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}